{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import win32gui\n",
    "from PIL import ImageGrab, Image\n",
    "import numpy as np\n",
    "from tkinter import messagebox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUI has been initialized, Go for the implementation\n"
     ]
    }
   ],
   "source": [
    "window=tk.Tk()\n",
    "window.title(\"Handwritten Digit Recognition GUI\")\n",
    "\n",
    "window = Canvas(window, width=550, height=200, bg='black')\n",
    "window.grid(row=0, column=0, pady=2, sticky=W, columnspan=2)\n",
    "\n",
    "print(\"GUI has been initialized, Go for the implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturing the image from paint and predicting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is: 9, Accuracy: 90%\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000019F0E0399D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Prediction is: 9, Accuracy: 90%\n"
     ]
    }
   ],
   "source": [
    "l1=tk.Label(window,text=\"Welcome to Digit Recognizer GUI\",font=('Arial',20),bg='black',fg='yellow')\n",
    "l1.place(x=50,y=5)\n",
    "\n",
    "def open_paint():\n",
    "    import os\n",
    "    os.startfile(\"C:/ProgramData/Microsoft/Windows/Start Menu/Programs/Accessories/Paint\")\n",
    "\n",
    "b1=tk.Button(window,text=\" Open Paint\", font=('Times new roman',16),activebackground=\"yellow\",activeforeground=\"black\",bg=\"ivory\",fg=\"black\",bd=6,command=open_paint)\n",
    "b1.place(x=70, y=70)\n",
    "\n",
    "def prediction():\n",
    "    import cv2   # pip install opencv-python\n",
    "    import numpy as np #pip install numpy\n",
    "    import time\n",
    "    import pyscreenshot as ImageGrab\n",
    "    import os\n",
    "    \n",
    "    model = load_model(r\"C:\\Users\\BISWAJIT\\Project\\Untitled Folder\\hdr.h5\")  ## loading our cnn model to the gui \n",
    "    images_folder=\"img/\"\n",
    "    #time.sleep(15)\n",
    "    \n",
    "   \n",
    "    image =ImageGrab.grab(bbox=(60,170,400,550))  ## capturing the screen dimension\n",
    "        \n",
    "    \n",
    "    image.save(images_folder+\"img.png\")\n",
    "    im1 = cv2.imread(images_folder+\"img.png\")\n",
    "    #im = im.resize((28,28))\n",
    "    #im = im.convert('L')\n",
    "    #im = np.array(im)\n",
    "    #im = im.reshape(1,28,28,1)\n",
    "    #im = im/255\n",
    "    \n",
    "    ## Reshaping the image to fit into the model\n",
    "    IMG_SIZE = 28\n",
    "    im = np.array(image)\n",
    "    #image = np.asarray(image)\n",
    "    grayim = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    resized = cv2.resize(grayim, (28,28), interpolation=cv2.INTER_AREA)\n",
    "    newim = tf.keras.utils.normalize(resized,axis=1)\n",
    "    newim = np.array(newim).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "                \n",
    "    predictions  =model.predict(newim)  ## fitting the image into the model\n",
    "    digit = np.argmax(predictions)\n",
    "    data = str(digit)+', Accuracy: '+str(int(max(predictions[0])*100))+'%'\n",
    "    acc = str(int(max(predictions[0])*100))+'%'\n",
    "    print(\"Prediction is:\",data)\n",
    "    \n",
    "        \n",
    "    cv2.putText(im1, \"Prediction is: \"+str(digit)+\", \"+acc, (20,20), 0, 0.8,(0,0,0),2,cv2.LINE_AA)\n",
    "        \n",
    "    cv2.startWindowThread()  #Starting another window to show the prediction result\n",
    "    cv2.namedWindow(\"Result\")\n",
    "    cv2.imshow(\"Result\",im1)\n",
    "    \n",
    "    (1000)\n",
    "        #if cv2.waitKey(1)==13: #27 is the ascii value of esc, 13 is the ascii value of enter\n",
    "         #   break\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "b2=tk.Button(window,text=\" Live Prediction\", font=('Times new roman',16),activebackground=\"yellow\",activeforeground=\"black\",bd=6,bg=\"ivory\",fg=\"black\",command=prediction)\n",
    "b2.place(x=250, y=70)\n",
    "\n",
    "\n",
    "#window.geometry(\"600x300\")\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
